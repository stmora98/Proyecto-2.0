# üßº **Parte 1: Limpieza de datos**

- **Eliminar duplicados:** Revisa el conjunto de datos y elimina las filas que est√©n repetidas para evitar inconsistencias.  
- **Normalizar nombres de pa√≠s:** Unifica los nombres de los pa√≠ses utilizando un mismo criterio de escritura y formato.  
- **Convertir fechas al formato est√°ndar:** Aseg√∫rate de que todas las fechas sigan el formato **DD/MM/AAAA**.  
- **Eliminar registros nulos o incompletos:** Descarta las filas que contengan datos faltantes o incompletos para mantener la calidad del an√°lisis.

## üß™ **C√≥digo**

```python
# Leer dataset unificado desde Bronze
df = spark.read.csv("Files/dataset_unificado.csv", header=True, inferSchema=True)

# Eliminar duplicados
df_clean = df.dropDuplicates()

# Normalizar nombres de pa√≠s
from pyspark.sql.functions import trim, upper

df_clean = df_clean.withColumn("pais", upper(trim(df_clean["pais"])))

# Convertir fechas al formato est√°ndar
from pyspark.sql.functions import to_date

df_clean = df_clean.withColumn("fecha", to_date(df_clean["fecha"], "yyyy-MM-dd"))

# Eliminar registros con campos nulos cr√≠ticos
df_clean = df_clean.dropna(subset=["customerId", "monto", "fecha"])

# Mostrar resultado limpio
display(df_clean)
```

# üìà **Parte 2: Enriquecimiento de datos**

- **M√©tricas derivadas por cliente**
- **Total gastado:** Suma total de las compras por cliente.
- **Frecuencia de compra:** N√∫mero de compras por cliente en el periodo.
- **Pa√≠s m√°s frecuente:** Pa√≠s desde el que el cliente compra con mayor frecuencia.

## üõ†Ô∏è **C√≥digo**

```Python
from pyspark.sql.functions import sum, count, col, first, desc

# Total gastado y frecuencia
df_metrics = df_clean.groupBy("customerId").agg(
    sum("monto").alias("total_gastado"),
    count("fecha").alias("frecuencia_compra"),
    first("pais").alias("pais_principal")  # simplificado, se puede mejorar con mode()
)

# Unir con datos demogr√°ficos
df_final = df_metrics.join(
    df_clean.select("customerId", "edad", "segmento").dropDuplicates(),
    on="customerId",
    how="left"
)

# Guardar en capa Silver
df_final.write.mode("overwrite").csv("Lakehouse/Silver/dataset_enriquecido.csv", header=True)

# Mostrar resultado enriquecido
display(df_final)
```

# üèÜ **Parte 3: Crear modelo sem√°ntico en capa Gold**

- **Crear tabla Gold desde archivo enriquecido:** Genera una tabla en la capa Gold utilizando el archivo ya enriquecido, asegurando que contiene solo los datos procesados y limpios.  
- **Definir medidas y dimensiones:** Establece claramente las medidas (m√©tricas cuantitativas) y dimensiones (atributos descriptivos) que formar√°n parte del modelo sem√°ntico.  
- **Publicar modelo para Power BI o Data Agent:** Publica el modelo sem√°ntico creado para que est√© disponible y pueda ser consultado desde Power BI o Data Agent seg√∫n las necesidades del negocio.

## üõ†Ô∏è **C√≥digo**
```python
# Leer desde Silver
df_gold = spark.read.csv("Lakehouse/Silver/dataset_enriquecido.csv", header=True, inferSchema=True)

# Guardar como tabla Gold
df_gold.write.mode("overwrite").saveAsTable("Gold.ClienteAnalitico")

# Verificar tabla
spark.sql("SELECT * FROM Gold.ClienteAnalitico LIMIT 10").show()
```

## Resultado esperado
- Datos limpios y enriquecidos listos en la capa Silver.
- Tabla sem√°ntica en la capa Gold con m√©tricas por cliente.

---

# Soluci√≥n Reto 03 ‚Äî Modelo Sem√°ntico, Data Agent y Dashboard (Capa Gold)

Objetivo
- Construir la capa Gold con medidas y dimensiones, crear el modelo sem√°ntico, exponerlo a trav√©s de un Data Agent y crear un dashboard en Power BI.

Requisitos previos
- Tablas Silver listas y validadas.
- Permisos para Power BI / Fabric y creaci√≥n de Data Agents.

## Pasos

### 1 ‚Äî Construir tablas Gold

1. Desde la Lakehouse, crea tablas Gold que incluyan agregaciones y relaciones claves (por ejemplo `gold.sales_agg`, `gold.product_dim`).
2. Define claves y tipos: `productID`, `customerID`, `date`.

### 2 ‚Äî Dise√±ar el modelo sem√°ntico

1. Abre Power BI Desktop (o el dise√±ador de modelos en Fabric).
2. Conecta al Lakehouse Gold y crea un modelo relacional: tablas de hechos y dimensiones.
3. A√±ade medidas DAX (o medidas computadas en Fabric):
- `valor_comercial_total = SUM([sales_amount])`
- `productos_disponibles = COUNTROWS(FILTER(products, products[availability] = "In Stock"))`

### 3 ‚Äî Validar modelo con queries y Copilot

1. Realiza preguntas clave en Power BI o Copilot para validar la consistencia (ej.: valor por marca, categor√≠a con m√°s productos valiosos).
2. Corrige relaciones o medidas si las respuestas no concuerdan.

### 4 ‚Äî Crear Data Agent conectado al modelo

1. En Fabric, crea un Data Agent y con√©ctalo al modelo sem√°ntico Gold.
2. Configura permisos y alcance (qu√© tablas/medidas puede consultar).
3. Prueba consultas en lenguaje natural para validar respuestas.

### 5 ‚Äî Dise√±ar Dashboard en Power BI

1. Crea un informe con visualizaciones clave:
- Score promedio por segmento
- Top productos por valor comercial
- Tendencias temporales (ventas mensuales)
2. Publica el informe en el workspace y enl√°zalo al modelo Gold.

## Chequeos finales
- El modelo devuelve respuestas correctas a preguntas de negocio.
- El Data Agent responde en lenguaje natural y sin exponer c√≥digo.
- Dashboard publicado y conectado al modelo Gold.
