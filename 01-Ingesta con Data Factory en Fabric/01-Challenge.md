# ğŸ† Reto 1: Ingesta de Datos desde Cosmos DB a Microsoft Fabric (Capa Bronze) + Limpieza BÃ¡sica  

ğŸ“– Escenario  
Contoso necesita consolidar sus **datos operativos** en **Microsoft Fabric**.  
El equipo de datos debe realizar la **ingesta desde Azure Cosmos DB** hacia la capa **Bronze** y aplicar una **limpieza inicial** para preparar los datos antes de avanzar a las siguientes fases de transformaciÃ³n.  

---

### ğŸ¯ Tu MisiÃ³n  
Al completar este reto podrÃ¡s:  

âœ… Ingerir los datos desde **Azure Cosmos DB** hacia **Microsoft Fabric** utilizando **Dataflows Gen2**.  
âœ… Aplicar una **limpieza bÃ¡sica** que incluya:  
- Manejo de valores nulos o vacÃ­os.  
- EliminaciÃ³n de columnas innecesarias.  
- NormalizaciÃ³n de formatos bÃ¡sicos (fechas, texto, etc.).  
âœ… Generar una tabla limpia dentro de la capa **Bronze** del Lakehouse.  

---

## ğŸš€ Paso 1: Crear un Dataflow Gen2 para la Ingesta desde Cosmos DB  
ğŸ’¡ *Â¿Por quÃ©?* Los **Dataflows Gen2** permiten realizar la ingesta y transformaciÃ³n inicial de datos sin necesidad de cÃ³digo, conectando fÃ¡cilmente fuentes externas como Cosmos DB con tu Lakehouse.  

1ï¸âƒ£ En **Microsoft Fabric**, crea un nuevo **Dataflow Gen2** dentro de tu workspace.  
ğŸ”¹ Selecciona **Azure Cosmos DB** como fuente de datos.  
ğŸ”¹ Ingresa las credenciales de conexiÃ³n (endpoint y clave de acceso).  
ğŸ”¹ Conecta con el contenedor que contiene los datos de **ventas** o **finanzas**.  
ğŸ”¹ Define como destino tu **Lakehouse (Bronze)** para almacenar los datos ingeridos.  

âœ… **Resultado esperado:** Los datos JSON de Cosmos DB se encuentran almacenados en la capa Bronze del Lakehouse.  

---

## ğŸš€ Paso 2: Validar la Carga y Estructura de los Datos  
ğŸ’¡ *Â¿Por quÃ©?* Validar la ingesta garantiza que los datos sean completos y coherentes antes de iniciar la limpieza.  

1ï¸âƒ£ Accede a tu **Lakehouse** desde el Dataflow o desde el panel de Fabric.  
ğŸ”¹ Revisa que las tablas o archivos creados contengan los campos esperados.  
ğŸ”¹ Comprueba que no existan errores de formato o registros incompletos.  

âœ… **Resultado esperado:** La estructura base de los datos ha sido validada correctamente.  

---

## ğŸš€ Paso 3: Aplicar Limpieza BÃ¡sica en el Dataflow Gen2  
ğŸ’¡ *Â¿Por quÃ©?* Este paso mejora la calidad de los datos, asegurando consistencia y usabilidad para anÃ¡lisis posteriores.  

1ï¸âƒ£ Edita tu **Dataflow Gen2** para agregar pasos de transformaciÃ³n:  
   - ğŸ§¹ **Eliminar columnas innecesarias** que no aporten valor analÃ­tico.  
   - ğŸ©¹ **Reemplazar o eliminar valores nulos o vacÃ­os.**  
   - ğŸ•’ **Normalizar formatos bÃ¡sicos** (por ejemplo, campos de fecha o texto en minÃºsculas).  
2ï¸âƒ£ Guarda y ejecuta el Dataflow para aplicar las transformaciones.  
3ï¸âƒ£ Publica los resultados en la **capa Bronze** de tu Lakehouse.  

âœ… **Resultado esperado:** La tabla â€œBronzeâ€ contiene datos limpios, estructurados y listos para su transformaciÃ³n en la capa Silver.  

---

## ğŸ Puntos de Control Finales  

âœ… Â¿Se completÃ³ la ingesta desde Cosmos DB mediante Dataflows Gen2?  
âœ… Â¿Se aplicaron correctamente las transformaciones bÃ¡sicas?  
âœ… Â¿Los datos resultantes estÃ¡n almacenados y accesibles en la capa Bronze?  
âœ… Â¿Se documentaron los pasos realizados y las evidencias visuales?  

---

## ğŸ“ DocumentaciÃ³n  


- [Creacion Dataflow Gen2](https://learn.microsoft.com/es-mx/fabric/data-factory/create-first-dataflow-gen2)



